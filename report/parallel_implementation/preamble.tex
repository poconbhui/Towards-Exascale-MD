Parallel implementations are required to be functionally equivalent
to the example serial implementations outlined in \SEC{sec:methodology:subsec:implementation}.
%
Tests may then be implemented straightforwardly for the serial implementation,
and are then easily extended to the parallel implementations.

The prescribed interface discourages the use of optimisations which make
assumptions about the MD algorithm being implemented.
%
If it were known ahead of time, for example, that
only forces would be updated during a \pairoperation{},
as is the case in the \velocityverlet{} algorithm,
or that inter-atomic forces dropped to zero after a given distance,
the implementation may be able to use this information to improve
performance through specialized data layouts or communications patterns.

Optimizations for particular algorithms and MD systems are
beyond the scope of this dissertation.
%
The focus here is on general communication patterns rather than
the optimization of particular MD algorithms.

Implementations of the \replicateddata{} and \systolicloop{} schemes
using only MPI will be analysed and discussed by focusing on
the scaling results of the \individualoperation{} and \pairoperation{} methods.


\input{parallel_implementation/replicated_data.tex}
\input{parallel_implementation/systolic_loop.tex}
\input{parallel_implementation/shared_and_replicated_data.tex}
\input{parallel_implementation/replicated_systolic_loop.tex}
